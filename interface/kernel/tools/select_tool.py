from kernel.agent_llm.rag.similarity_search import get_most_similar_tool
from kernel.agent_llm.llm.llm import llm_prompt


conversation_history = []

def analyze_tool_to_use(user_prompt, tools, tool_embeddings):
    """
    Analyzes the user's prompt to determine the most suitable tool to use based on the provided embeddings.

    Parameters:
    user_prompt (str): The user's input prompt.
    tools (dict): A dictionary of available tools with their corresponding functions.
    tool_embeddings (list): A list of embeddings for the tools to match against the user prompt.

    Returns:
    str: The response generated by the selected tool or the classic LLM if no tool matches.
    """
    global conversation_history
    if conversation_history != []:
        conversation_history = conversation_history
    else:
        conversation_history = []

    similar_tool = get_most_similar_tool(user_prompt, tool_embeddings)
    if similar_tool:
        conversation_history = []
        tool_function = tools[similar_tool]["function"]
        
        #------------ Adapt here and paste the code depending on tools downloaded --------
        # Set parameters based on selected tool
        if similar_tool in ["search_ytb", "search_google", "search_wikipedia", "search_bing", "vocal_note"]:
            param = user_prompt
        else:
            param = None
        # --------------------------------------------------------------------------------
        
        # Call the tool function with the appropriate parameter
        if param is not None:
            response = tool_function(param)
        else:
            response = tool_function()
        
        return response
    else:
        # If no tool correspond, enter prompt in classic LLM to have discussion
        response = llm_prompt(user_prompt, conversation_history)
        return response